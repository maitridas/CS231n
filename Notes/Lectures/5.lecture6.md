## Training Neural Network

!["Problem"](./images/lecture6/img1.JPG)

!["Problem"](./images/lecture6/img2.JPG)

!["Problem"](./images/lecture6/img3.JPG)

!["Problem"](./images/lecture6/img4.JPG)

!["Problem"](./images/lecture6/img5.JPG)

### Sigmoid function

!["Problem"](./images/lecture6/img6.JPG)

- What does the first problem means?

!["Problem"](./images/lecture6/img7.JPG)

- x= -10 gradient is 0, kill off the gradient and not going to get gradient flow
- x= 0 gradient is ok
- x= 10 gradient is 0, kill off the gradient and not going to get gradient flow

Second problem with sigmoid func is -

!["Problem"](./images/lecture6/img8.JPG)

!["Problem"](./images/lecture6/img9.JPG)

!["Problem"](./images/lecture6/img10.JPG)

Inefficient gradient updates , w will increase or decrease in the same direction, see the zig zag part we are only allowed to travel the w value in the red path , whereas we could have just travelled along blue line. Suboptimal Optimization.

That why we need 0 mean so that we have +ve and -ve values and don't run into such problems.

Third problem with sigmoid func is -

!["Problem"](./images/lecture6/img11.JPG)

### tanh

!["Problem"](./images/lecture6/img12.JPG)

Looks similar to sigmoid difference is its zero centered.

### ReLU

!["Problem"](./images/lecture6/img13.JPG)

Does not saturate in positive reason.

!["Problem"](./images/lecture6/img14.JPG)

- x=10 ->linear
- x=0 -> undefined but in practice we say its 0
- x=-10 -> 0  killing the gradient

!["Problem"](./images/lecture6/img15.JPG)

Bad relu reason

- bad initialization
- learning rate too high

Saturated gradient becomes 0 so it does not updates the values.

How do you know whether the relu is dead or not wrt the data cloud?

- Not answered

People initialize ReLU with slighty positive biases in order to initialize and get active ReLU and get some updates.

### Modified ReLU

!["Problem"](./images/lecture6/img16.JPG)

### ELU

!["Problem"](./images/lecture6/img17.JPG)

### Maxout

!["Problem"](./images/lecture6/img18.JPG)

### In practice

!["Problem"](./images/lecture6/img19.JPG)

## Data Preprossesing

!["Problem"](./images/lecture6/img20.JPG)

we do zero center to images.

We want to normalize so that all features are in the same range and they contribute equally.

For images we don't generally normalize images because pixles are usually of the same range. 

!["Problem"](./images/lecture6/img21.JPG)

We don't do this in images.

!["Problem"](./images/lecture6/img22.JPG)

In practice we ussually calculate mean and apply the same mean in test and train data.

We will have 3 means 1 mean for the green 1 for blue 1 for red

Mean is taken over all the training images

Data preprocessing does solve the zero mean problem for the first layer, but comes back at later layers 

## Weight Initialization

!["Problem"](./images/lecture6/img23.JPG)

- All neurons will do the same thing
- same output 
- same gradient
- which we don't want
- we want neurons to learn different things.

!["Problem"](./images/lecture6/img24.JPG)

It will work for small networks but can be problem for deeper networks.

!["Problem"](./images/lecture6/img25.JPG)

!["Problem"](./images/lecture6/img26.JPG)

- so our gradients are x and since x is small we are getting a small value and the gradients are not updating.

!["Problem"](./images/lecture6/img27.JPG)

- If weights are big its going to be saturated regine of tanh.All gradients 0 and weights not updating.

Good initialization Xavier Initialization//Check it out in lecture notes

!["Problem"](./images/lecture6/img28.JPG)

!["Problem"](./images/lecture6/img29.JPG)

!["Problem"](./images/lecture6/img30.JPG)

## Read papers to know about initializations

!["Problem"](./images/lecture6/img31.JPG)

## Batch Normalizations

- Wanting to keep activations in the Gaussian Range.

!["Problem"](./images/lecture6/img32.JPG)

!["Problem"](./images/lecture6/img33.JPG)

!["Problem"](./images/lecture6/img34.JPG)

!["Problem"](./images/lecture6/img35.JPG)

-> did not understand the last picture

!["Problem"](./images/lecture6/img36.JPG)

!["Problem"](./images/lecture6/img37.JPG)

## Babysitting the Learning Process

### Step 2 

!["Problem"](./images/lecture6/img38.JPG)

!["Problem"](./images/lecture6/img39.JPG)

!["Problem"](./images/lecture6/img40.JPG)

!["Problem"](./images/lecture6/img41.JPG)

One best practice is that -
- start with a very small amount of data so we can overfit and get a good training loss
- turn of the regularization again and just see if we can make the loss go to zero.

!["Problem"](./images/lecture6/img42.JPG)

!["Problem"](./images/lecture6/img43.JPG)

!["Problem"](./images/lecture6/img44.JPG)

We get NaN because our cost exploded and reason for this is our learning rate too high.

!["Problem"](./images/lecture6/img45.JPG)

### Hyperparameter Optimization

!["Problem"](./images/lecture6/img46.JPG)

!["Problem"](./images/lecture6/img47.JPG)

!["Problem"](./images/lecture6/img48.JPG) 

And so the problem is that we can see that our best accuracy here has a learning rate that's about, you know, all of our good learning rates are in this E to the negative four range.

Right, and since the learning rate that we specified was going from 10 to the negative four to 10 to the zero, that means that all the good learning rates, were at the edge of the range that we were sampling. And so this is bad, because this means that we might not have explored our space sufficiently, right. We might actually want to go to 10 to the negative five, or 10 to the negative six. There might be still better ranges if we continue shifting down. So, you want to make sure that your range kind of has the good values somewhere in the middle, or somewhere where you get a sense that you've hit, you've explored your range fully. 

!["Problem"](./images/lecture6/img49.JPG) 

 we can sample all of our different hyperparameters, using a kind of grid search, right. We can sample for a fixed set of combinations, a fixed set of values for each hyperparameter. Sample in a grid manner over all of these values, but in practice it's actually better to sample from a random layout, so sampling random value of each hyperparameter in a range. And so what you'll get instead is we'll have these two hyper parameters here that we want to sample from. You'll get samples that look like this right side instead. And the reason for this is that if a function is really sort of more of a function of one variable than another, which is usually true. Usually we have little bit more, a lower effective dimensionality than we actually have. Then you're going to get many more samples of the important variable that you have. You're going to be able to see this shape in this green function that I've drawn on top, showing where the good values are, compared to if you just did a grid layout where we were only able to sample three values here, and you've missed where were the good regions. Right, and so basically we'll get much more useful signal overall since we have more samples of different values of the important variable. 

 !["Problem"](./images/lecture6/img50.JPG)

 !["Problem"](./images/lecture6/img51.JPG)

 !["Problem"](./images/lecture6/img52.JPG)

 !["Problem"](./images/lecture6/img53.JPG)

 !["Problem"](./images/lecture6/img54.JPG)

 !["Problem"](./images/lecture6/img55.JPG)

 Taking norm to measure how large they are

 !["Problem"](./images/lecture6/img56.JPG)